{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-1",
   "metadata": {},
   "source": "# Tutoriel ArcticDB - Stocker et gérer des données financières\n\nArcticDB est une base de données orientée colonnes, optimisée pour les séries temporelles et les données financières.  \nElle permet de stocker des DataFrames pandas directement, sans conversion, et offre des performances élevées en lecture/écriture.\n\n**Ce que vous allez apprendre :**\n1. Créer une connexion ArcticDB (stockage local avec LMDB)\n2. Créer des bibliothèques (libraries)\n3. Écrire et lire des données (actions boursières)\n4. Mettre à jour des données (append)\n5. Versionner les données\n6. Filtrer et requêter les données\n7. Requêter avec DuckDB (SQL sur les données ArcticDB)\n8. Supprimer des données"
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Imports et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcticdb as adb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Connexion à ArcticDB\n",
    "\n",
    "ArcticDB supporte plusieurs backends de stockage : LMDB (local), S3, Azure Blob Storage.  \n",
    "Pour ce tutoriel, nous utilisons **LMDB** qui stocke les données localement sur disque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-connect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion locale avec LMDB\n",
    "arctic = adb.Arctic(\"lmdb://arcticdb_data\")\n",
    "print(f\"Connexion établie : {arctic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Créer une bibliothèque (Library)\n",
    "\n",
    "Une **library** est l'équivalent d'une base de données ou d'un schéma.  \n",
    "On y regroupe des symboles (tables) par thématique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer (ou récupérer) une bibliothèque\n",
    "lib = arctic.get_library(\"actions_fr\", create_if_missing=True)\n",
    "\n",
    "# Lister les bibliothèques existantes\n",
    "print(\"Bibliothèques disponibles :\", arctic.list_libraries())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Télécharger des données financières avec yfinance\n",
    "\n",
    "Nous allons récupérer les cours de quelques actions pour les stocker dans ArcticDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-download",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste de tickers à télécharger\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "\n",
    "# Télécharger 1 mois de données pour chaque ticker\n",
    "donnees = {}\n",
    "for ticker in tickers:\n",
    "    df = yf.download(ticker, period=\"1mo\")\n",
    "    # Aplatir les colonnes multi-niveaux de yfinance\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    donnees[ticker] = df\n",
    "    print(f\"{ticker} : {len(df)} lignes téléchargées\")\n",
    "\n",
    "# Aperçu des données Apple\n",
    "donnees[\"AAPL\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Écrire des données dans ArcticDB\n",
    "\n",
    "La méthode `write()` stocke un DataFrame sous un **symbole** (nom de la table).  \n",
    "Chaque écriture crée automatiquement une nouvelle version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-write",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrire chaque ticker comme un symbole distinct\n",
    "for ticker, df in donnees.items():\n",
    "    info = lib.write(ticker, df)\n",
    "    print(f\"Écrit : {ticker} -> version {info.version}\")\n",
    "\n",
    "# Lister les symboles dans la bibliothèque\n",
    "print(\"\\nSymboles stockés :\", lib.list_symbols())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. Lire des données depuis ArcticDB\n",
    "\n",
    "La méthode `read()` retourne un objet `VersionedItem` contenant le DataFrame dans `.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-read",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire les données Apple\n",
    "result = lib.read(\"AAPL\")\n",
    "\n",
    "print(f\"Symbole : {result.symbol}\")\n",
    "print(f\"Version : {result.version}\")\n",
    "print(f\"Shape   : {result.data.shape}\")\n",
    "print()\n",
    "result.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. Ajouter des données (Append)\n",
    "\n",
    "La méthode `append()` permet d'ajouter de nouvelles lignes à un symbole existant.  \n",
    "C'est idéal pour les mises à jour quotidiennes de cours boursiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-append",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuler de nouvelles données pour demain\n",
    "derniere_date = donnees[\"AAPL\"].index[-1]\n",
    "nouvelle_date = derniere_date + timedelta(days=1)\n",
    "\n",
    "nouvelles_donnees = pd.DataFrame(\n",
    "    {\n",
    "        \"Close\": [260.50],\n",
    "        \"High\": [262.00],\n",
    "        \"Low\": [258.00],\n",
    "        \"Open\": [259.00],\n",
    "        \"Volume\": [50000000],\n",
    "    },\n",
    "    index=pd.DatetimeIndex([nouvelle_date], name=\"Date\"),\n",
    ")\n",
    "\n",
    "# Ajouter au symbole existant\n",
    "info = lib.append(\"AAPL\", nouvelles_donnees)\n",
    "print(f\"Append effectué -> version {info.version}\")\n",
    "\n",
    "# Vérifier que la ligne a été ajoutée\n",
    "df_updated = lib.read(\"AAPL\").data\n",
    "print(f\"Nombre de lignes : {len(df_updated)}\")\n",
    "df_updated.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8. Versionning des données\n",
    "\n",
    "ArcticDB garde un historique de toutes les versions d'un symbole.  \n",
    "On peut relire n'importe quelle version antérieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-versions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrire une deuxième version (écriture complète, pas un append)\n",
    "df_modifie = donnees[\"AAPL\"].copy()\n",
    "df_modifie[\"Close\"] = df_modifie[\"Close\"] * 1.05  # Simuler +5%\n",
    "lib.write(\"AAPL\", df_modifie)\n",
    "\n",
    "# Lister toutes les versions\n",
    "versions = lib.list_versions(\"AAPL\")\n",
    "print(\"Versions disponibles pour AAPL :\")\n",
    "for v in versions:\n",
    "    print(f\"  Version {v['version']}\")\n",
    "\n",
    "# Lire une version spécifique (la première : version 0)\n",
    "ancienne = lib.read(\"AAPL\", as_of=0)\n",
    "actuelle = lib.read(\"AAPL\")\n",
    "\n",
    "print(f\"\\nVersion 0 - Close moyen : {ancienne.data['Close'].mean():.2f}\")\n",
    "print(f\"Dernière version - Close moyen : {actuelle.data['Close'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "## 9. Filtrage avec QueryBuilder\n",
    "\n",
    "ArcticDB permet de filtrer les données directement au niveau du stockage,  \n",
    "ce qui est beaucoup plus rapide que de charger tout le DataFrame puis filtrer avec pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-query",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcticdb import QueryBuilder\n",
    "\n",
    "# Filtrer : uniquement les jours où le volume dépasse 45 millions\n",
    "q = QueryBuilder()\n",
    "q = q[q[\"Volume\"] > 45_000_000]\n",
    "\n",
    "resultat = lib.read(\"AAPL\", as_of=0, query_builder=q)\n",
    "print(\"Jours avec volume > 45M :\")\n",
    "resultat.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9b",
   "metadata": {},
   "source": [
    "### Filtrage par plage de dates (Date Range)\n",
    "\n",
    "On peut aussi limiter la lecture à une plage de dates spécifique  \n",
    "en utilisant le paramètre `date_range`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-daterange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire uniquement les 5 premiers jours\n",
    "df_original = lib.read(\"AAPL\", as_of=0).data\n",
    "date_debut = df_original.index[0]\n",
    "date_fin = df_original.index[4] if len(df_original) > 4 else df_original.index[-1]\n",
    "\n",
    "resultat_dates = lib.read(\n",
    "    \"AAPL\",\n",
    "    as_of=0,\n",
    "    date_range=(date_debut, date_fin),\n",
    ")\n",
    "print(f\"Données du {date_debut.date()} au {date_fin.date()} :\")\n",
    "resultat_dates.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g8y7rttitog",
   "source": "## 10. Requêter avec DuckDB\n\nDuckDB peut requêter directement des DataFrames pandas en mémoire avec du SQL.  \nCombiné à ArcticDB, cela permet de :\n- **Stocker** les données avec ArcticDB (versioning, append, stockage optimisé)\n- **Analyser** les données avec DuckDB (SQL complet, agrégations, jointures)\n\nC'est le meilleur des deux mondes : stockage spécialisé + requêtes SQL puissantes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "mq7o42qh98h",
   "source": "import duckdb\n\n# Charger les données depuis ArcticDB dans des DataFrames pandas\naapl = lib.read(\"AAPL\", as_of=0).data\nmsft = lib.read(\"MSFT\").data\n\n# DuckDB peut requêter directement les variables pandas !\n# Requête simple : les 5 jours avec le plus gros volume pour Apple\nduckdb.sql(\"\"\"\n    SELECT Date, Close, Volume\n    FROM aapl\n    ORDER BY Volume DESC\n    LIMIT 5\n\"\"\").show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "lyoyyqnko2a",
   "source": "### Agrégations SQL",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ia89386iijn",
   "source": "# Statistiques agrégées\nduckdb.sql(\"\"\"\n    SELECT\n        round(avg(Close), 2)  AS close_moyen,\n        round(min(Low), 2)    AS plus_bas,\n        round(max(High), 2)   AS plus_haut,\n        sum(Volume)           AS volume_total,\n        count(*)              AS nb_jours\n    FROM aapl\n\"\"\").show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "laanjdz9vcj",
   "source": "### Jointures entre symboles\n\nDuckDB permet de croiser facilement les données de plusieurs actions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4uk5dhff36s",
   "source": "# Comparer Apple et Microsoft jour par jour\nduckdb.sql(\"\"\"\n    SELECT\n        a.Date,\n        round(a.Close, 2) AS aapl_close,\n        round(m.Close, 2) AS msft_close,\n        round(a.Close - m.Close, 2) AS ecart,\n        CASE WHEN a.Volume > m.Volume THEN 'AAPL' ELSE 'MSFT' END AS plus_echange\n    FROM aapl a\n    JOIN msft m ON a.Date = m.Date\n    ORDER BY a.Date\n\"\"\").show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "lucehf3rw5p",
   "source": "### Résultat SQL vers pandas\n\nOn peut aussi récupérer le résultat DuckDB directement en DataFrame pandas pour continuer l'analyse.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3f47ieoijum",
   "source": "# Convertir le résultat SQL en DataFrame pandas\ndf_rendements = duckdb.sql(\"\"\"\n    SELECT\n        Date,\n        Close,\n        round((Close - lag(Close) OVER (ORDER BY Date)) / lag(Close) OVER (ORDER BY Date) * 100, 2)\n            AS rendement_pct\n    FROM aapl\n    ORDER BY Date\n\"\"\").df()\n\n# Le résultat est un DataFrame pandas classique\nprint(type(df_rendements))\ndf_rendements.dropna()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "section-10",
   "metadata": {},
   "source": "## 11. Métadonnées\n\nOn peut associer des métadonnées (dictionnaire Python) à chaque symbole.  \nUtile pour stocker la source, la devise, la fréquence, etc."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrire avec des métadonnées\n",
    "metadata = {\n",
    "    \"source\": \"yfinance\",\n",
    "    \"devise\": \"USD\",\n",
    "    \"frequence\": \"journalier\",\n",
    "    \"description\": \"Cours Apple Inc.\",\n",
    "}\n",
    "\n",
    "lib.write(\"AAPL\", donnees[\"AAPL\"], metadata=metadata)\n",
    "\n",
    "# Relire les métadonnées\n",
    "result = lib.read(\"AAPL\")\n",
    "print(\"Métadonnées associées :\")\n",
    "for cle, valeur in result.metadata.items():\n",
    "    print(f\"  {cle}: {valeur}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-11",
   "metadata": {},
   "source": "## 12. Suppression\n\nOn peut supprimer un symbole spécifique ou vider une bibliothèque entière."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-delete",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer un symbole\n",
    "lib.delete(\"GOOGL\")\n",
    "print(\"Après suppression de GOOGL :\", lib.list_symbols())\n",
    "\n",
    "# Supprimer une bibliothèque entière\n",
    "# arctic.delete_library(\"actions_fr\")\n",
    "# print(\"Bibliothèques restantes :\", arctic.list_libraries())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-12",
   "metadata": {},
   "source": "## 13. Résumé des commandes principales\n\n| Opération | Méthode | Description |\n|-----------|---------|-------------|\n| Connexion | `adb.Arctic(\"lmdb://chemin\")` | Se connecter au stockage |\n| Créer library | `arctic.get_library(nom, create_if_missing=True)` | Créer/récupérer une bibliothèque |\n| Écrire | `lib.write(symbole, df)` | Stocker un DataFrame |\n| Lire | `lib.read(symbole)` | Lire les données |\n| Ajouter | `lib.append(symbole, df)` | Ajouter des lignes |\n| Versions | `lib.list_versions(symbole)` | Lister les versions |\n| Lire version | `lib.read(symbole, as_of=n)` | Lire une version spécifique |\n| Filtrer | `lib.read(symbole, query_builder=q)` | Filtrer avec QueryBuilder |\n| SQL (DuckDB) | `duckdb.sql(\"SELECT ... FROM df\")` | Requêtes SQL sur les DataFrames |\n| SQL -> pandas | `duckdb.sql(\"...\").df()` | Résultat SQL en DataFrame |\n| Supprimer | `lib.delete(symbole)` | Supprimer un symbole |\n| Lister | `lib.list_symbols()` | Lister tous les symboles |"
  },
  {
   "cell_type": "markdown",
   "id": "section-13",
   "metadata": {},
   "source": [
    "## Pour aller plus loin\n",
    "\n",
    "- **Stockage S3** : `adb.Arctic(\"s3://bucket/chemin?region=eu-west-1\")` pour un stockage cloud\n",
    "- **Performances** : ArcticDB gère des milliards de lignes efficacement grâce au stockage colonnaire\n",
    "- **Documentation** : [docs.arcticdb.io](https://docs.arcticdb.io)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}